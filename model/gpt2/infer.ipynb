{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 介绍\n",
    "这个是`chinese-gpt2`的推理代码\n",
    "1. 将`model_name_or_path = \"checkpoint-36000\"`里面的`\"checkpoint-36000\"`,修改为模型所在的路径。\n",
    "2. 然后运行下面一个代码块，即可输出文本生成结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoTokenizer\n",
    "\n",
    "model_name_or_path = \"/root/model/gpt2/train/chinese_gpt2_big/checkpoint-60000\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name_or_path, pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "你 是 谁 ？ 我 们 是 不 是 已 经 在 一 起 了 ？, 简 单 的 描 述 是, 答 案 是 你 好 ， 我 是 一 个 女 孩 子 ， 她 是 我 的 女 朋 友 。 我 很 喜 欢 她 ， 也 很 爱 她 。 但 是 ， 你 不 知 道 她 为 什 么 对 我 这 么 好 。 因 为 我 觉 得 自 己 是 个 很 好 的 人 ， 所 以 我 不 想 让 她 受 到 伤 害 。 她 说 ： 如 果 你 真 的 爱 我 ， 那 么 我 一 定 会 为 你 做 很 多 事 情 的 。 我 想 ， 这 个 世 界 上 ， 只 有 两 种 人 ： 一 种 是 真 心 爱 你 的 ， 另 一 类 是 没 有 真 正 爱 过 你 。 你 们 之 间 的 关 系 ， 就 像 是 两 个 人 的 感 情 一 样 ， 不 可 能 永 远 维 持 下 去 。 而 且 ， 爱 情 是\n"
     ]
    }
   ],
   "source": [
    "txt = \"\"\"\\\n",
    "你是谁\n",
    "\"\"\"\n",
    "# encode context the generation is conditioned on\n",
    "input_ids = tokenizer.encode(txt, return_tensors='pt', add_special_tokens=False)\n",
    "# set no_repeat_ngram_size to 2\n",
    "beam_output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=200, \n",
    "    num_beams=5, \n",
    "    no_repeat_ngram_size=2, \n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(input):\n",
    "    input_ids = tokenizer.encode(input, return_tensors='pt', add_special_tokens=False)\n",
    "    # set no_repeat_ngram_size to 2\n",
    "    beam_output = model.generate(\n",
    "        input_ids, \n",
    "        max_length=200, \n",
    "        num_beams=5, \n",
    "        no_repeat_ngram_size=2, \n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    print(\"Output:\\n\" + 100 * '-')\n",
    "    print(tokenizer.decode(beam_output[0], skip_special_tokens=True))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "大 语 言 模 型 可 以 做 什 么 ？, 简 单 的 描 述 是, 答 案 是 一 、 模 拟 人 工 智 能 的 基 本 概 念 （ 1 ） 人 类 的 智 慧 （ 2 ） 机 器 学 习 （ 3 ） 计 算 机 视 觉 技 术 （ 4 ） 数 据 处 理 （ 5 ） 语 音 识 别 （ 6 ） 自 动 驾 驶 （ 7 ） 电 子 商 务 （ 8 ） 网 络 安 全 （ 9 ） 信 息 系 统 （ 10 ） 物 联 网 （ 11 ） 无 人 机 （ 12 ） 航 空 航 天 工 程 （ 13 ） 飞 行 器 制 造 （ 14 ） 通 信 （ 15 ） 工 业 控 制 （ 16 ） 生 物 医 药 （ 17 ） 医 疗 器 械 （ 18 ） 环 境 保 护 （ 19 ） 食 品 药 品 （ 20 ） 化 学 制 剂 （ 21 ） 有 机 化 工 （ 22 ） 农 业 （ 23 ） 水 产 养 殖 （ 24 ）\n"
     ]
    }
   ],
   "source": [
    "get_output('大语言模型可以做什么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "树 上 三 只 鸟 ， 飞 走 了 一 只 ， 还 剩 几 只 ？, 简 单 的 描 述 是, 答 案 是 你 好 ！ 这 是 一 个 很 有 趣 的 问 题 ， 我 们 都 知 道 ， 鸟 是 人 类 的 一 种 生 物 ， 它 们 生 活 在 大 自 然 的 怀 抱 中 ， 在 这 个 世 界 上 ， 每 个 动 物 都 有 自 己 独 特 的 生 存 方 式 ， 但 是 ， 人 们 却 没 有 意 识 到 它 的 存 在 ， 因 为 它 只 有 在 生 命 的 最 后 一 刻 ， 才 能 够 活 下 去 。 这 就 是 为 什 么 有 人 说 ： 人 生 在 世 ， 只 要 活 着 ， 就 可 以 活 得 很 好 。 那 么 ， 如 果 你 有 这 样 的 想 法 ， 你 会 怎 么 做 呢 ？ 我 觉 得 有 两 个 方 面 的 原 因 ： 第 一 ， 这 种 思 想\n"
     ]
    }
   ],
   "source": [
    "get_output('树上三只鸟，飞走了一只，还剩几只？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4e9266737a3d6b71b60265cf120055eda92ec7823ffe2a0ed53da8b39d4a1eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
