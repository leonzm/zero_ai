{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "001ba2ac",
   "metadata": {},
   "source": [
    "# [Bert-base-Chinese 微调](https://blog.csdn.net/qq_43668800/article/details/131921617)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe6d915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32fbfa7",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e3cb83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cuda\n"
     ]
    }
   ],
   "source": [
    "# 优先使用 GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device=', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e925879d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练模型\n",
    "pretrained = BertModel.from_pretrained('bert-base-chinese')\n",
    "# 需要移动到cuda上\n",
    "pretrained.to(device)\n",
    "\n",
    "# 不训练,不需要计算梯度\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7ad9f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义下游任务模型\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        with torch.no_grad():\n",
    "            out = pretrained(input_ids=input_ids,\n",
    "                             attention_mask=attention_mask,\n",
    "                             token_type_ids=token_type_ids)\n",
    "\n",
    "        out = self.fc(out.last_hidden_state[:, 0])\n",
    "        out = out.softmax(dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = Model()\n",
    "# 同样要移动到cuda\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8afecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "913135fe",
   "metadata": {},
   "source": [
    "## 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66644bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration lansinuote--ChnSentiCorp-4d058ef86e3db8d5\n",
      "Reusing dataset parquet (/root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--ChnSentiCorp-4d058ef86e3db8d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--ChnSentiCorp-4d058ef86e3db8d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-3f28c458f01cdeac.arrow\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# 定义数据集\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, split):\n",
    "        dataset = load_dataset(path='lansinuote/ChnSentiCorp', split=split)\n",
    "\n",
    "        def f(data):\n",
    "            return len(data['text']) > 40\n",
    "        self.dataset = dataset.filter(f)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        text = self.dataset[i]['text']\n",
    "        # 切分一句话为前半句和后半句\n",
    "        sentence1 = text[:20]\n",
    "        sentence2 = text[20:40]\n",
    "        label = 0\n",
    "        # 有一半的概率把后半句替换为一句无关的话\n",
    "        if random.randint(0, 1) == 0:\n",
    "            j = random.randint(0, len(self.dataset) - 1)\n",
    "            sentence2 = self.dataset[j]['text'][20:40]\n",
    "            label = 1\n",
    "        return sentence1, sentence2, label\n",
    "\n",
    "\n",
    "dataset = Dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10380208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载字典和分词工具\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77436160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[CLS] 酒 店 附 近 修 路, 出 行 比 较 痛 苦. 服 务 还 是 一 如 [SEP] 些 小. 另 空 调 [UNK] 的 制 冷 效 果 也 不 行. 不 过 门 童 [SEP] [PAD] [PAD]\n",
      "torch.Size([8, 45]) torch.Size([8, 45]) torch.Size([8, 45]) tensor([1, 1, 0, 0, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(data):\n",
    "    sents = [i[:2] for i in data]\n",
    "    labels = [i[2] for i in data]\n",
    "\n",
    "    # 编码\n",
    "    data = tokenizer.batch_encode_plus(batch_text_or_text_pairs=sents,\n",
    "                                   truncation=True,\n",
    "                                   padding='max_length',\n",
    "                                   max_length=45,\n",
    "                                   return_tensors='pt',\n",
    "                                   return_length=True,\n",
    "                                   add_special_tokens=True)\n",
    "    # input_ids:编码之后的数字\n",
    "    # attention_mask:是补零的位置是0,其他位置是1\n",
    "    # token_type_ids:第一个句子和特殊符号的位置是0,第二个句子的位置是1\n",
    "    input_ids = data['input_ids'].to(device)\n",
    "    attention_mask = data['attention_mask'].to(device)\n",
    "    token_type_ids = data['token_type_ids'].to(device)\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    # print(data['length'], data['length'].max())\n",
    "    return input_ids, attention_mask, token_type_ids, labels\n",
    "\n",
    "\n",
    "# 数据加载器\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=8,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "for i, (input_ids, attention_mask, token_type_ids,\n",
    "        labels) in enumerate(loader):\n",
    "    break\n",
    "\n",
    "print(len(loader))\n",
    "print(tokenizer.decode(input_ids[0]))\n",
    "print(input_ids.shape, attention_mask.shape, token_type_ids.shape, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad9aa1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a2b0105",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c41fa5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2024-03-17 07:22:15.286990\n",
      "0 0.6786895394325256 0.625\n",
      "5 0.6797517538070679 0.5\n",
      "10 0.5397366285324097 0.875\n",
      "15 0.6062564849853516 0.75\n",
      "20 0.3825371563434601 1.0\n",
      "25 0.47723689675331116 0.875\n",
      "30 0.5387418270111084 0.875\n",
      "35 0.5455511808395386 0.75\n",
      "40 0.4515652060508728 0.875\n",
      "45 0.4244160056114197 1.0\n",
      "50 0.5319026112556458 0.75\n",
      "55 0.43289244174957275 0.875\n",
      "60 0.38636234402656555 1.0\n",
      "65 0.4123062789440155 1.0\n",
      "70 0.5459636449813843 0.75\n",
      "75 0.5019277334213257 0.75\n",
      "80 0.5108401775360107 0.875\n",
      "85 0.43392840027809143 0.875\n",
      "90 0.3742237985134125 1.0\n",
      "95 0.5382683873176575 0.75\n",
      "100 0.40421730279922485 0.875\n",
      "105 0.38905826210975647 1.0\n",
      "110 0.5289791822433472 0.75\n",
      "115 0.32093340158462524 1.0\n",
      "120 0.39357060194015503 1.0\n",
      "125 0.33106929063796997 1.0\n",
      "130 0.5883960723876953 0.625\n",
      "135 0.557947039604187 0.75\n",
      "140 0.3755119740962982 1.0\n",
      "145 0.3446900546550751 1.0\n",
      "150 0.3895173668861389 0.875\n",
      "155 0.3325086832046509 1.0\n",
      "160 0.3174254894256592 1.0\n",
      "165 0.579171895980835 0.75\n",
      "170 0.3227245509624481 1.0\n",
      "175 0.4435458779335022 0.875\n",
      "180 0.43268251419067383 1.0\n",
      "185 0.3238210082054138 1.0\n",
      "190 0.444837361574173 0.875\n",
      "195 0.6009350419044495 0.625\n",
      "200 0.3651081323623657 1.0\n",
      "205 0.3655511438846588 1.0\n",
      "210 0.5329838991165161 0.75\n",
      "215 0.4068559408187866 0.875\n",
      "220 0.4288730323314667 0.875\n",
      "225 0.4640299081802368 0.875\n",
      "230 0.37017107009887695 1.0\n",
      "235 0.36724743247032166 1.0\n",
      "240 0.5424754619598389 0.75\n",
      "245 0.5775174498558044 0.75\n",
      "250 0.4476577341556549 0.875\n",
      "255 0.4530603289604187 0.875\n",
      "260 0.3352477550506592 1.0\n",
      "265 0.4004162847995758 0.875\n",
      "270 0.464997798204422 0.875\n",
      "275 0.482051283121109 0.875\n",
      "280 0.4080103933811188 1.0\n",
      "285 0.5081093907356262 0.75\n",
      "290 0.4518200755119324 0.875\n",
      "295 0.5000129342079163 0.875\n",
      "300 0.6688470244407654 0.625\n",
      "End time: 2024-03-17 07:22:23.676086\n",
      "Consume time of second: 8\n"
     ]
    }
   ],
   "source": [
    "import time, datetime\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print('Start time:', start_time)\n",
    "\n",
    "# 训练\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader):\n",
    "    out = model(input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids)\n",
    "    loss = criterion(out, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if i % 5 == 0:\n",
    "        out = out.argmax(dim=1)\n",
    "        accuracy = (out == labels).sum().item() / len(labels)\n",
    "        print(i, loss.item(), accuracy)\n",
    "    if i == 300:\n",
    "        break\n",
    "\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print('End time:', end_time)\n",
    "\n",
    "consume_time = end_time - start_time\n",
    "print('Consume time of second:', consume_time.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe51178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87441eb5",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fe49aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration lansinuote--ChnSentiCorp-4d058ef86e3db8d5\n",
      "Reusing dataset parquet (/root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--ChnSentiCorp-4d058ef86e3db8d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--ChnSentiCorp-4d058ef86e3db8d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-b2e870d062ef5600.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.9125\n",
      "10 0.875\n",
      "15 0.8625\n",
      "20 0.8703125\n",
      "25 0.87125\n",
      "0.8677083333333333\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loader_test = torch.utils.data.DataLoader(dataset=Dataset('test'),\n",
    "                                              batch_size=32,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=True)\n",
    "    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader_test):\n",
    "        if i%5 == 0 and total != 0:\n",
    "            print(i, correct / total)\n",
    "        with torch.no_grad():\n",
    "            out = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == labels).sum().item()\n",
    "        total += len(labels)\n",
    "    print(correct / total)\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5081cba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8945bd6",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52ac531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存至: /root/workspace/model/model_bert-base-chinese/sentence_correlation.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_path = '/root/workspace/model/model_bert-base-chinese/sentence_correlation.pt'\n",
    "# torch.save(model.state_dict(), model_path)\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print('模型已保存至:', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b63a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9de013da",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84a6f94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = Model()\n",
    "my_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96c6db51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(the_model, two_sent_arr):\n",
    "    the_model.eval()\n",
    "    # 优先使用 GPU\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print('device=', device)\n",
    "    the_model.to(device)\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "    torch.no_grad()\n",
    "    x_encode = tokenizer.batch_encode_plus(\n",
    "        # 传入的所有句子，有成对句子\n",
    "        batch_text_or_text_pairs=two_sent_arr,\n",
    "        # 长度大于设置是否截断\n",
    "        truncation=True,\n",
    "        # 一律补齐，如果长度不够\n",
    "        padding='max_length',\n",
    "        add_special_tokens=True,\n",
    "        max_length=45,\n",
    "        # 可取值tf,pt,np,（tensorflow,pytorch,numpy）默认返回list\n",
    "        return_tensors=\"pt\",\n",
    "        # 返回token_type_ids,第一句与特殊符号是0，第二句是1\n",
    "        return_token_type_ids=True,\n",
    "        # 返回attention_mask，填充是0，其他是1\n",
    "        return_attention_mask=True,\n",
    "        # 返回special_tokens_mask特殊符号标识，特殊是1，其他是0\n",
    "        return_special_tokens_mask=True,\n",
    "        # 返回长度,这里的长度是真实长度，而非设置的长度30了\n",
    "        return_length=True\n",
    "    )\n",
    "\n",
    "    y = the_model(input_ids=x_encode['input_ids'].to(device),\n",
    "                  attention_mask=x_encode['attention_mask'].to(device),\n",
    "                  token_type_ids=x_encode['token_type_ids'].to(device))\n",
    "    # print(y)\n",
    "    res = y.argmax(dim=1)\n",
    "    return res.cpu().numpy().tolist()\n",
    "\n",
    "\n",
    "two_sents = [['这家店不错，总体环境很好，服务也很热情', '好评，希望生意越来越好'], \n",
    "             ['这家店环境太差，服务冷淡', '再也不还来'], \n",
    "             ['这家店不错，总体环境很好', '可以再考虑再次光临'],\n",
    "             ['这家店不错，总体环境很好', '我要投诉']]\n",
    "predict(my_model, two_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362bf67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65195c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62caea3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882cb05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc61d76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9103b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff793c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
